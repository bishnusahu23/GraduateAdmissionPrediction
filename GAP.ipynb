{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"admission_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   GRE Score          500 non-null    int64  \n",
      " 1   TOEFL Score        500 non-null    int64  \n",
      " 2   University Rating  500 non-null    int64  \n",
      " 3   SOP                500 non-null    float64\n",
      " 4   LOR                500 non-null    float64\n",
      " 5   CGPA               500 non-null    float64\n",
      " 6   Research           500 non-null    int64  \n",
      " 7   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(4)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns='Chance of Admit ')\n",
    "y=df['Chance of Admit ']\n",
    "\n",
    "train_x, test_x, train_y, test_y= train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 7), (400,), (100, 7), (100,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_x.shape,train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "train_x=scaler.fit_transform(train_x)\n",
    "test_x=scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62      , 0.67857143, 0.5       , ..., 0.71428571, 0.65064103,\n",
       "        1.        ],\n",
       "       [0.52      , 0.67857143, 0.75      , ..., 1.        , 0.55769231,\n",
       "        0.        ],\n",
       "       [0.26      , 0.35714286, 0.5       , ..., 0.42857143, 0.54487179,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.24      , 0.25      , 0.        , ..., 0.14285714, 0.14423077,\n",
       "        0.        ],\n",
       "       [0.38      , 0.46428571, 0.25      , ..., 0.71428571, 0.28205128,\n",
       "        0.        ],\n",
       "       [0.48      , 0.5       , 0.25      , ..., 0.57142857, 0.46474359,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kerastuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 07:48:14.554987: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-30 07:48:20.761314: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-30 07:48:25.512363: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730274509.477686    2025 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730274510.504867    2025 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-30 07:48:40.875640: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model=Sequential()\n",
    "\n",
    "    counter=0\n",
    "   \n",
    "    for i in range( hp.Int('num_layers',1,10)):\n",
    "        if counter==0:\n",
    "            model.add(Dense(hp.Int('units' +str(i),8,128,step=8), \n",
    "                            activation=hp.Choice('activation' + str(i),['relu','leaky-relu','elu']),input_dim=7))\n",
    "            \n",
    "        else:\n",
    "            model.add(Dense(hp.Int('units' +str(i),8,128,step=8), \n",
    "                            activation=hp.Choice('activation' + str(i),['relu','leaky-relu','elu'])))\n",
    "        counter+=1\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "     \n",
    "    optimizer=hp.Choice('optimizer',values=['adam','sgd','rmsprop','adadelta'])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 02s]\n",
      "val_loss: 0.0045702215284109116\n",
      "\n",
      "Best val_loss So Far: 0.0045702215284109116\n",
      "Total elapsed time: 00h 00m 07s\n"
     ]
    }
   ],
   "source": [
    "tuner=kt.RandomSearch(build_model, objective='val_loss',max_trials=5, directory='mydir', project_name='project1')\n",
    "tuner.search(train_x,train_y,epochs=5, validation_data=(test_x,test_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 7,\n",
       " 'units0': 24,\n",
       " 'activation0': 'relu',\n",
       " 'optimizer': 'rmsprop',\n",
       " 'units1': 8,\n",
       " 'activation1': 'elu',\n",
       " 'units2': 8,\n",
       " 'activation2': 'relu',\n",
       " 'units3': 32,\n",
       " 'activation3': 'elu',\n",
       " 'units4': 120,\n",
       " 'activation4': 'elu',\n",
       " 'units5': 8,\n",
       " 'activation5': 'relu',\n",
       " 'units6': 8,\n",
       " 'activation6': 'relu'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │         \u001b[38;5;34m3,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,761</span> (22.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,761\u001b[0m (22.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,761</span> (22.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,761\u001b[0m (22.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0060\n",
      "Epoch 7/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 8/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 9/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 10/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 11/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 12/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 13/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 14/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 15/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 16/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 17/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 18/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 19/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 20/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 21/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 22/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 23/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 24/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 25/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 26/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 27/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 28/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 29/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 30/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 31/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 32/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 33/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 34/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 35/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 36/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 37/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 38/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 39/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 40/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 41/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 42/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 43/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 44/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 45/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 46/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 47/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 48/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 49/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 50/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 51/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 52/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 53/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 54/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 55/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 56/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 57/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0089\n",
      "Epoch 58/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 59/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 60/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0062\n",
      "Epoch 61/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 62/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 63/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 64/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 65/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 66/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 67/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 68/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 69/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 70/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 71/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 72/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 73/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 74/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 75/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 76/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 77/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 78/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 79/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 80/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 81/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 82/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 83/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 84/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 85/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 86/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 87/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 88/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 89/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 90/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 91/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 92/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 93/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 94/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 95/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 96/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 97/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0090\n",
      "Epoch 98/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 99/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 100/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 101/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0065\n",
      "Epoch 102/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 103/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 104/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 105/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 106/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 107/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0039\n",
      "Epoch 108/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 109/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 110/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 111/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 112/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 113/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 114/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 115/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 116/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 117/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 118/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 119/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 120/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 121/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 122/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 123/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 124/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 125/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 126/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 127/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 128/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 129/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 130/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 131/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 132/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 133/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 134/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 135/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 136/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 137/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 138/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 139/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 140/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 141/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 142/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 143/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 144/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 145/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 146/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 147/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 148/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 149/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 150/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 151/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0058\n",
      "Epoch 152/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 153/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 154/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 155/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 156/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 157/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 158/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 159/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 160/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 161/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 162/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 163/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 164/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 165/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 166/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 167/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 168/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 169/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 170/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0052\n",
      "Epoch 171/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 172/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 173/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 174/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 175/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0056\n",
      "Epoch 176/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0051\n",
      "Epoch 177/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 178/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 179/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 180/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 181/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 182/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 183/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 184/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 185/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 186/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 187/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 188/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 189/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 190/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 191/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 192/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 193/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 194/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 195/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 196/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 197/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 198/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 199/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 200/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 201/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 202/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 203/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 204/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 205/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 206/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 207/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 208/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 209/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 210/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 211/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0073\n",
      "Epoch 212/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 213/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 214/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 215/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 216/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 217/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 218/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 219/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 220/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 221/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 222/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 223/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 224/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 225/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 226/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 227/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - val_loss: 0.0039\n",
      "Epoch 228/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 229/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 230/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 231/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 232/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 233/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 234/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 235/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 236/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 237/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 238/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 239/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0056\n",
      "Epoch 240/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 241/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 242/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 243/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 244/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 245/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 246/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 247/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 248/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 249/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 250/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 251/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 252/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 253/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 254/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 255/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 256/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0053\n",
      "Epoch 257/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0054\n",
      "Epoch 258/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 259/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 260/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 261/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 262/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 263/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 264/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 265/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 266/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 267/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 268/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 269/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 270/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 271/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 272/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 273/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 274/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 275/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 276/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 277/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 278/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 279/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Epoch 280/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 281/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 282/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 283/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0053\n",
      "Epoch 284/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 285/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 286/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 287/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 288/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 289/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 290/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 291/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 292/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 293/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 294/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0057\n",
      "Epoch 295/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 296/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 297/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 - val_loss: 0.0045\n",
      "Epoch 298/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0041\n",
      "Epoch 299/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 300/300\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x75ce9508afc0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,epochs=300, initial_epoch=5, validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7697921025205299"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred=model.predict(test_x)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_y,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without hyperpatameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(7,activation='relu',input_dim=7))\n",
    "model2.add(Dense(14,activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m15\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183</span> (732.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m183\u001b[0m (732.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">183</span> (732.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m183\u001b[0m (732.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='Adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4210 - val_loss: 0.2501\n",
      "Epoch 2/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2959 - val_loss: 0.1477\n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1830 - val_loss: 0.0876\n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1114 - val_loss: 0.0619\n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0877 - val_loss: 0.0552\n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0711 - val_loss: 0.0516\n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0665 - val_loss: 0.0455\n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0557 - val_loss: 0.0386\n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0456 - val_loss: 0.0326\n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0412 - val_loss: 0.0276\n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0321 - val_loss: 0.0238\n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0274 - val_loss: 0.0208\n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0245 - val_loss: 0.0188\n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0226 - val_loss: 0.0172\n",
      "Epoch 15/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0210 - val_loss: 0.0157\n",
      "Epoch 16/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0179 - val_loss: 0.0144\n",
      "Epoch 17/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 18/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 19/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 20/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 21/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 22/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 23/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 24/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 25/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 26/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 27/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 28/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 29/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 30/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0085\n",
      "Epoch 31/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 32/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 33/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 34/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 35/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 36/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 37/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 38/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 39/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 40/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 41/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - val_loss: 0.0072\n",
      "Epoch 42/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 43/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 44/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 45/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 46/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 47/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 48/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 49/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 50/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 51/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 52/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 53/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 54/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 55/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 56/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 57/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 58/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 - val_loss: 0.0060\n",
      "Epoch 59/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0060\n",
      "Epoch 60/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 61/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 62/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 63/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 64/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 65/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 66/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 67/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 68/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 69/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 70/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0053\n",
      "Epoch 71/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 72/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 73/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 74/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 75/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 76/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 77/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 78/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 79/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 80/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 81/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 82/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0052 - val_loss: 0.0046\n",
      "Epoch 83/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 84/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 85/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 86/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 87/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 88/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 89/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 90/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 91/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 92/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 93/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 94/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 95/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 96/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 97/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 98/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 99/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 100/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 101/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 102/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 103/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 104/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 105/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 106/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 107/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 108/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 109/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 110/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 111/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 112/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 113/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 114/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 115/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 116/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 117/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 118/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 119/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 120/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 121/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 122/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 123/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 124/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 125/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 126/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 127/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 128/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 129/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 130/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 131/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 132/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 133/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 134/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 135/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 136/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 137/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 138/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 139/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 140/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 141/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 142/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 143/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 144/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 145/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 146/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 147/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 148/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 149/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 150/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 151/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 152/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 153/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 154/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 155/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 156/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 157/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 158/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 159/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 160/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 161/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 162/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 163/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 164/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 165/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss',patience=3)\n",
    "history=model2.fit(train_x,train_y,epochs=200,validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8162164028249839"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred=model2.predict(test_x)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_y,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5823/646815123.py:4: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], color='red')\n",
    "plt.plot(history.history['val_loss'], color='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
